@article{dhiman2022,
  title = {Methodological Conduct of Prognostic Prediction Models Developed Using Machine Learning in Oncology: A Systematic Review},
  shorttitle = {Methodological Conduct of Prognostic Prediction Models Developed Using Machine Learning in Oncology},
  author = {Dhiman, Paula and Ma, Jie and Andaur Navarro, Constanza L. and Speich, Benjamin and Bullock, Garrett and Damen, Johanna A. A. and Hooft, Lotty and Kirtley, Shona and Riley, Richard D. and Van Calster, Ben and Moons, Karel G. M. and Collins, Gary S.},
  year = {2022},
  month = apr,
  journal = {BMC Medical Research Methodology},
  volume = {22},
  number = {1},
  pages = {101},
  issn = {1471-2288},
  doi = {10.1186/s12874-022-01577-x},
  urldate = {2023-07-31},
  abstract = {Describe and evaluate the methodological conduct of prognostic prediction models developed using machine learning methods in oncology.},
  keywords = {Machine learning,Methodology,Prediction},
  file = {/Users/ewan/Zotero/storage/WPZSQ4T9/Dhiman et al. - 2022 - Methodological conduct of prognostic prediction mo.pdf}
}

@article{meehan2022,
  title = {Clinical Prediction Models in Psychiatry: A Systematic Review of Two Decades of Progress and Challenges},
  shorttitle = {Clinical Prediction Models in Psychiatry},
  author = {Meehan, Alan J. and Lewis, Stephanie J. and Fazel, Seena and {Fusar-Poli}, Paolo and Steyerberg, Ewout W. and Stahl, Daniel and Danese, Andrea},
  year = {2022},
  month = jun,
  journal = {Molecular Psychiatry},
  volume = {27},
  number = {6},
  pages = {2700--2708},
  publisher = {{Nature Publishing Group}},
  issn = {1476-5578},
  doi = {10.1038/s41380-022-01528-4},
  urldate = {2023-07-31},
  abstract = {Recent years have seen the rapid proliferation of clinical prediction models aiming to support risk stratification and individualized care within psychiatry. Despite growing interest, attempts to synthesize current evidence in the nascent field of precision psychiatry have remained scarce. This systematic review therefore sought to summarize progress towards clinical implementation of prediction modeling for psychiatric outcomes. We searched MEDLINE, PubMed, Embase, and PsychINFO databases from inception to September 30, 2020, for English-language articles that developed and/or validated multivariable models to predict (at an individual level) onset, course, or treatment response for non-organic psychiatric disorders (PROSPERO: CRD42020216530). Individual prediction models were evaluated based on three key criteria: (i) mitigation of bias and overfitting; (ii) generalizability, and (iii) clinical utility. The Prediction model Risk Of Bias ASsessment Tool (PROBAST) was used to formally appraise each study's risk of bias. 228 studies detailing 308 prediction models were ultimately eligible for inclusion. 94.5\% of developed prediction models were deemed to be at high risk of bias, largely due to inadequate or inappropriate analytic decisions. Insufficient internal validation efforts (within the development sample) were also observed, while only one-fifth of models underwent external validation in an independent sample. Finally, our search identified just one published model whose potential utility in clinical practice was formally assessed. Our findings illustrated significant growth in precision psychiatry with promising progress towards real-world application. Nevertheless, these efforts have been inhibited by a preponderance of bias and overfitting, while the generalizability and clinical utility of many published models has yet to be formally established. Through improved methodological rigor during initial development, robust evaluations of reproducibility via independent validation, and evidence-based implementation frameworks, future research has the potential to generate risk prediction tools capable of enhancing clinical decision-making in psychiatric care.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Psychiatric disorders,Psychology},
  file = {/Users/ewan/Zotero/storage/PDD7B25P/Meehan et al. - 2022 - Clinical prediction models in psychiatry a system.pdf}
}

@article{navarro2021,
  title = {Risk of Bias in Studies on Prediction Models Developed Using Supervised Machine Learning Techniques: Systematic Review},
  shorttitle = {Risk of Bias in Studies on Prediction Models Developed Using Supervised Machine Learning Techniques},
  author = {Navarro, Constanza L. Andaur and Damen, Johanna A. A. and Takada, Toshihiko and Nijman, Steven W. J. and Dhiman, Paula and Ma, Jie and Collins, Gary S. and Bajpai, Ram and Riley, Richard D. and Moons, Karel G. M. and Hooft, Lotty},
  year = {2021},
  month = oct,
  journal = {BMJ},
  volume = {375},
  pages = {n2281},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {1756-1833},
  doi = {10.1136/bmj.n2281},
  urldate = {2023-07-31},
  abstract = {Objective To assess the methodological quality of studies on prediction models developed using machine learning techniques across all medical specialties. Design Systematic review. Data sources PubMed from 1 January 2018 to 31 December 2019. Eligibility criteria Articles reporting on the development, with or without external validation, of a multivariable prediction model (diagnostic or prognostic) developed using supervised machine learning for individualised predictions. No restrictions applied for study design, data source, or predicted patient related health outcomes. Review methods Methodological quality of the studies was determined and risk of bias evaluated using the prediction risk of bias assessment tool (PROBAST). This tool contains 21 signalling questions tailored to identify potential biases in four domains. Risk of bias was measured for each domain (participants, predictors, outcome, and analysis) and each study (overall). Results 152 studies were included: 58 (38\%) included a diagnostic prediction model and 94 (62\%) a prognostic prediction model. PROBAST was applied to 152 developed models and 19 external validations. Of these 171 analyses, 148 (87\%, 95\% confidence interval 81\% to 91\%) were rated at high risk of bias. The analysis domain was most frequently rated at high risk of bias. Of the 152 models, 85 (56\%, 48\% to 64\%) were developed with an inadequate number of events per candidate predictor, 62 handled missing data inadequately (41\%, 33\% to 49\%), and 59 assessed overfitting improperly (39\%, 31\% to 47\%). Most models used appropriate data sources to develop (73\%, 66\% to 79\%) and externally validate the machine learning based prediction models (74\%, 51\% to 88\%). Information about blinding of outcome and blinding of predictors was, however, absent in 60 (40\%, 32\% to 47\%) and 79 (52\%, 44\% to 60\%) of the developed models, respectively. Conclusion Most studies on machine learning based prediction models show poor methodological quality and are at high risk of bias. Factors contributing to risk of bias include small study size, poor handling of missing data, and failure to deal with overfitting. Efforts to improve the design, conduct, reporting, and validation of such studies are necessary to boost the application of machine learning based prediction models in clinical practice. Systematic review registration PROSPERO CRD42019161764.},
  chapter = {Research},
  copyright = {\textcopyright{} Author(s) (or their employer(s)) 2019. Re-use permitted under CC BY. No commercial re-use. See rights and permissions. Published by BMJ.. http://creativecommons.org/licenses/by/4.0/This is an Open Access article distributed in accordance with the terms of the Creative Commons Attribution (CC BY 4.0) license, which permits others to distribute, remix, adapt and build upon this work, for commercial use, provided the original work is properly cited. See: http://creativecommons.org/licenses/by/4.0/.},
  langid = {english},
  pmid = {34670780},
  file = {/Users/ewan/Zotero/storage/I6UMSBFH/Navarro et al. - 2021 - Risk of bias in studies on prediction models devel.pdf}
}

@article{vansmeden2016,
  title = {No Rationale for 1 Variable per 10 Events Criterion for Binary Logistic Regression Analysis},
  author = {{van Smeden}, Maarten and {de Groot}, Joris A. H. and Moons, Karel G. M. and Collins, Gary S. and Altman, Douglas G. and Eijkemans, Marinus J. C. and Reitsma, Johannes B.},
  year = {2016},
  month = nov,
  journal = {BMC Medical Research Methodology},
  volume = {16},
  number = {1},
  pages = {163},
  issn = {1471-2288},
  doi = {10.1186/s12874-016-0267-3},
  urldate = {2023-07-31},
  abstract = {Ten events per variable (EPV) is a widely advocated minimal criterion for sample size considerations in logistic regression analysis. Of three previous simulation studies that examined this minimal EPV criterion only one supports the use of a minimum of 10 EPV. In this paper, we examine the reasons for substantial differences between these extensive simulation studies.},
  keywords = {Bias,EPV,Logistic regression,Sample size,Separation,Simulations},
  file = {/Users/ewan/Zotero/storage/LMP9GXS2/van Smeden et al. - 2016 - No rationale for 1 variable per 10 events criterio.pdf;/Users/ewan/Zotero/storage/NYSG7YFW/s12874-016-0267-3.html}
}

@article{wynants2020,
  title = {Prediction Models for Diagnosis and Prognosis of Covid-19: Systematic Review and Critical Appraisal},
  shorttitle = {Prediction Models for Diagnosis and Prognosis of Covid-19},
  author = {Wynants, Laure and Calster, Ben Van and Collins, Gary S. and Riley, Richard D. and Heinze, Georg and Schuit, Ewoud and Albu, Elena and Arshi, Banafsheh and Bellou, Vanesa and Bonten, Marc M. J. and Dahly, Darren L. and Damen, Johanna A. and Debray, Thomas P. A. and de Jong, Valentijn M. T. and Vos, Maarten De and Dhiman, Paula and Ensor, Joie and Gao, Shan and Haller, Maria C. and Harhay, Michael O. and Henckaerts, Liesbet and Heus, Pauline and Hoogland, Jeroen and Hudda, Mohammed and Jenniskens, Kevin and Kammer, Michael and Kreuzberger, Nina and Lohmann, Anna and Levis, Brooke and Luijken, Kim and Ma, Jie and Martin, Glen P. and McLernon, David J. and Navarro, Constanza L. Andaur and Reitsma, Johannes B. and Sergeant, Jamie C. and Shi, Chunhu and Skoetz, Nicole and Smits, Luc J. M. and Snell, Kym I. E. and Sperrin, Matthew and Spijker, Ren{\'e} and Steyerberg, Ewout W. and Takada, Toshihiko and Tzoulaki, Ioanna and van Kuijk, Sander M. J. and van Bussel, Bas C. T. and van der Horst, Iwan C. C. and Reeve, Kelly and van Royen, Florien S. and Verbakel, Jan Y. and Wallisch, Christine and Wilkinson, Jack and Wolff, Robert and Hooft, Lotty and Moons, Karel G. M. and van Smeden, Maarten},
  year = {2020},
  month = apr,
  journal = {BMJ},
  volume = {369},
  pages = {m1328},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {1756-1833},
  doi = {10.1136/bmj.m1328},
  urldate = {2023-08-16},
  abstract = {Objective To review and appraise the validity and usefulness of published and preprint reports of prediction models for prognosis of patients with covid-19, and for detecting people in the general population at increased risk of covid-19 infection or being admitted to hospital or dying with the disease. Design Living systematic review and critical appraisal by the covid-PRECISE (Precise Risk Estimation to optimise covid-19 Care for Infected or Suspected patients in diverse sEttings) group. Data sources PubMed and Embase through Ovid, up to 17 February 2021, supplemented with arXiv, medRxiv, and bioRxiv up to 5 May 2020. Study selection Studies that developed or validated a multivariable covid-19 related prediction model. Data extraction At least two authors independently extracted data using the CHARMS (critical appraisal and data extraction for systematic reviews of prediction modelling studies) checklist; risk of bias was assessed using PROBAST (prediction model risk of bias assessment tool). Results 126 978 titles were screened, and 412 studies describing 731 new prediction models or validations were included. Of these 731, 125 were diagnostic models (including 75 based on medical imaging) and the remaining 606 were prognostic models for either identifying those at risk of covid-19 in the general population (13 models) or predicting diverse outcomes in those individuals with confirmed covid-19 (593 models). Owing to the widespread availability of diagnostic testing capacity after the summer of 2020, this living review has now focused on the prognostic models. Of these, 29 had low risk of bias, 32 had unclear risk of bias, and 545 had high risk of bias. The most common causes for high risk of bias were inadequate sample sizes (n=408, 67\%) and inappropriate or incomplete evaluation of model performance (n=338, 56\%). 381 models were newly developed, and 225 were external validations of existing models. The reported C indexes varied between 0.77 and 0.93 in development studies with low risk of bias, and between 0.56 and 0.78 in external validations with low risk of bias. The Qcovid models, the PRIEST score, Carr's model, the ISARIC4C Deterioration model, and the Xie model showed adequate predictive performance in studies at low risk of bias. Details on all reviewed models are publicly available at https://www.covprecise.org/. Conclusion Prediction models for covid-19 entered the academic literature to support medical decision making at unprecedented speed and in large numbers. Most published prediction model studies were poorly reported and at high risk of bias such that their reported predictive performances are probably optimistic. Models with low risk of bias should be validated before clinical implementation, preferably through collaborative efforts to also allow an investigation of the heterogeneity in their performance across various populations and settings. Methodological guidance, as provided in this paper, should be followed because unreliable predictions could cause more harm than benefit in guiding clinical decisions. Finally, prediction modellers should adhere to the TRIPOD (transparent reporting of a multivariable prediction model for individual prognosis or diagnosis) reporting guideline. Systematic review registration Protocol https://osf.io/ehc47/, registration https://osf.io/wy245. Readers' note This article is the final version of a living systematic review that has been updated over the past two years to reflect emerging evidence. This version is update 4 of the original article published on 7 April 2020 (BMJ 2020;369:m1328). Previous updates can be found as data supplements (https://www.bmj.com/content/369/bmj.m1328/related\#datasupp). When citing this paper please consider adding the update number and date of access for clarity.},
  chapter = {Research},
  copyright = {\textcopyright{} Author(s) (or their employer(s)) 2019. Re-use permitted under CC BY. No commercial re-use. See rights and permissions. Published by BMJ.. http://creativecommons.org/licenses/by/4.0/This is an Open Access article distributed in accordance with the terms of the Creative Commons Attribution (CC BY 4.0) license, which permits others to distribute, remix, adapt and build upon this work, for commercial use, provided the original work is properly cited. See: http://creativecommons.org/licenses/by/4.0/.},
  langid = {english},
  pmid = {32265220},
  file = {/Users/ewan/Zotero/storage/HT38RX2F/Wynants et al. - 2020 - Prediction models for diagnosis and prognosis of c.pdf}
}
